<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html>
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    <meta http-equiv="Content-Style-Type" content="text/css">
    <title></title>
    <style type="text/css">
     header { margin: 0.0px 0.0px 0.0px 0.0px; color: #525252; -webkit-text-stroke: #525252; }
     table.title { background-color: #f9f9f9; font: 12.0px Helvetica; color: #525252; -webkit-text-stroke: #525252;}

     h1 {text-align: center; font: 24.0px Geneva; color: #181818; -webkit-text-stroke: #000000;}
     .title p { font: 16.0px Geneva; margin: 0; paddding: 0; text-align: center; }
     .title p.name { font: 20.0px Geneva; font-weight: bold; margin: 0; paddding: 0; text-align: center; }
     
     h2 { text-align: center; font: 28.0px Helvetica; -webkit-text-stroke: #000000; min-height: 34.0px; }

     div.body { margin: 18px; }
     div.body p { font: 16px Geneva; text-align: center; margin: 0; paddding: 0; }

     .abstract { margin: 18px; border-style: solid; border-width: 2px; border-color: #0; border-collapse: collapse; padding: 9px; }
     .abstract p { margin: 0; font: 14px Geneva; }
     .abstract h3 { margin: 0; text-align: center; font: 16px Geneva; font-weight: bold; }
     
     .bio { margin: 18px; padding: 0px 9px 0px 9px; }
     .bio p { margin: 0; font: 14px Geneva; }
     .bio h3 { margin: 0;  text-align: center; font: 16px Geneva; font-weight: bold; }

     header, footer { margin: 0px; padding: 2px 9px 2px 9px; background-color: #f9f9f9; font: 12.0px Helvetica; color: #525252; -webkit-text-stroke: #525252; }

     .logo { margin: 0px; padding: 0px 9px 0px 9px; text-align: center; background-color: #0a2648; }
     p.logo { text-align: center; margin: 0; paddding: 0; }
    </style>
  </head>
  <body>
    <header>
      <p>FIU SCIS's Faculty Candidate Talk Series presents Kaidi Xu speaking on the topic of "Can We Trust AI? Towards Practical Implementation and Theoretical Analysis in Trustworthy Machine Learning", Monday, February 22, 2021, 2:00pm-3:00pm, via <a href="https://fiu.zoom.us/j/3053484802?pwd=VDhKLzJIck0wK0xZMFVxQ2lSUmVvZz09">Zoom.</a></p>
    </header>

     <div class="logo">
      <center>
        <table border="0" cellspacing="0" width="100%"><tr><td>
          <p style="margin:0; padding:0" class="logo"><img src="cid:fiu-logo.png" alt="School of Computing and Information Sciences, Florida International University" /></p>
        </td></tr>
        </table>
      </center>
    </div>

    <div class="title">
      <h1>Faculty Candidate Talk Series</h1>

     <center>
      <table border="0" cellspacing="0" width="30%"><tr><td width="250">
        <p><img style="max-width:250px; margin:0; padding:0;" src="cid:images/2021-02-22-Kaidu-Xu.jpg"></p>
      </td></tr>
      </table>
      </center>

      <p class="name">Kaidi Xu</p>
      <p>Ph.D. Candidate </p>
      <p>Northeastern University</p>

      <h2>Can We Trust AI? Towards Practical Implementation and Theoretical Analysis in Trustworthy Machine Learning</h2>
    </div>
    
    <div class="body">
      <p>When: <b>Monday, February 22, 2021, 2:00pm-3:00pm</b></p>
      <p>Where: <a href="https://fiu.zoom.us/j/3053484802?pwd=VDhKLzJIck0wK0xZMFVxQ2lSUmVvZz09"><b>Zoom</b></a></p>
      <p>Host: Jason Liu<p>
    </div>

    <div class="abstract">
      <h3>Abstract:</h3>
      <p>Deep learning has achieved extraordinary performance in many application domains recently. It has been well accepted that DNNs are vulnerable to adversarial attacks, which raises concerns of DNNs in security-critical applications and may result in disastrous consequences. Adversarial attacks are usually implemented by generating adversarial examples, i.e., adding sophisticated perturbations onto benign examples, such that adversarial examples are classified by the DNN as target (wrong) labels instead of the correct labels of the benign examples. The adversarial machine learning aims to study this phenomenon and leverage it to build robust machine learning systems and explain DNNs. In this talk, I will present the mechanism of adversarial machine learning in both empirical and theoretical ways. Specifically, a uniform adversarial attack generation framework, structured attack (StrAttack) is introduced, which explores group sparsity in adversarial perturbations by sliding a mask through images aiming for extracting key spatial structures. Second, we discuss the feasibility of adversarial attacks in the physical world and introduce a convincing framework, Expectation over Transformation (EoT). Utilize EoT with Thin Plate Spline (TPS) transformation, we can generate  Adversarial T-shirts, a powerful physical adversarial patch for evading person detectors even if it could undergo non-rigid deformation due to a moving personâ€™s pose changes. Third, we stand on the defense side and design the first adversarial training method based on Graph Neural Network. Finally, we introduce Linear relaxation-based perturbation analysis (LiRPA) for neural networks, which computes provable linear bounds of output neurons given a certain amount of input perturbation. LiRPA studies the adversarial example in a theoretical way and can guarantee the test accuracy of a model by given perturbation constraints. The generality, flexibility, efficiency and ease-of-use of our proposed framework facilitate the adoption of LiRPA based provable methods for other machine learning problems beyond robustness verification.</p>
    </div>

    <div class="bio">
      <h3>Bio:</h3>
      <p>Kaidi Xu is a Ph.D. candidate at Northeastern University. His research mainly focuses on the robustness of machine learning, including adversarial attacks, formal robustness verification and certified defenses. Besides trustworthy machine learning, he also has broad research interests include model compression & acceleration and explainable AI. His research papers are published in various top conferences such as NeurIPS, ICML, ICLR, IJCAI, AAAI, CVPR, ECCV, ICCV, etc. He also received multiple student travel awards at top conferences and serves as a committee member or reviewer in different conferences and journals. Previously to Northeastern University, He obtained his M.S. and B.S. degrees from the Department of Computer Science at the University of Florida in 2017 and Sichuan University in 2015 respectively.</p>
    </div>

    <footer>
      <p>This event will be webcast live, and archived. Join via <a href="https://fiu.zoom.us/j/3053484802?pwd=VDhKLzJIck0wK0xZMFVxQ2lSUmVvZz09">Zoom</a>. Meeting ID: 305 348 4802, Computer Passcode:  case349, Phone call Passcode: 5522441</p>
    </footer>

    <!-- <div class="logo">
         <center>
         <table border="0" cellspacing="0" width="100%"><tr><td>
         <p style="margin:0; padding:0" class="logo"><img src="cid:fiu-logo.png" alt="School of Computing and Information Sciences, Florida International University" /></p>
         </td></tr>
         </table>
         </center>
         </div> -->
  </body>
</html>
